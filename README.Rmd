---
title: "\"Bayesian\" Fisher Exact Test in Stan"
author: "TJ Mahr"
date: "May 14, 2017"
output: github_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(
  echo = TRUE,
  collapse = TRUE,
  comment = "#>")
```

This repository is an example I'm borrowing from [this talk by Bob
Carpenter](https://www.youtube.com/watch?v=qQFF4tPgeWI).


## Problem

We observed the following data.

```{r}
library(tibble)
library(dplyr, warn.conflicts = FALSE)

df <- tribble(
  ~ Sex, ~ Handedness, ~ n,
  "male", "left",  9,
  "male", "right", 43,
  "female", "left", 4,
  "female", "right", 44
)

knitr::kable(df)
```

Is the rate of left-handedness different between men and women? 

I'm not sure what this test is doing, but it's what one would do in
classical statistics.

```{r}
# Create a matrix for the test
m <- tidyr::spread(df, Handedness, n) %>% 
  as.data.frame()
rownames(m) <- m$Sex
m$Sex <- NULL
m

fisher.test(m)
fisher.test(m, alternative = "less")
```

## Fit the model in Stan

But I know Stan so I can compute a posterior probability of the difference
between men and women.

I think that 10% of people are left handed. I don't know where I heard this 
number first, but it'll serve as my prior information. I messed around with `shape1` 
and `shape2` until I got the follow prior, which is peaked around .1-ish and keeps .5
and .15 as still plausible values.

```{r}
plot(density(rbeta(100000, shape1 = 9, shape2 = 80)))
```

I write out a really simple model in Stan.

```{stan, output.var = "stan_model"}
# This knitr block also creates a `stan_model()` object in R called `stan_model`
data {
  int<lower=0> n_total_1;
  int<lower=0> n_total_2;
  int<lower=0> n_hits_1;
  int<lower=0> n_hits_2;
}
parameters { 
  real<lower=0, upper=1> theta_1;
  real<lower=0, upper=1> theta_2;
}
model {
  theta_1 ~ beta(9, 80);
  theta_2 ~ beta(9, 80);
  n_hits_1 ~ binomial(n_total_1, theta_1);
  n_hits_2 ~ binomial(n_total_2, theta_2);
}
generated quantities {
  real diff;
  diff = theta_1 - theta_2;
}
```

And fit it.

```{r}
stan_data <- list(
  n_total_1 = 9 + 43,
  n_total_2 = 3 + 44,
  n_hits_1 = 9,
  n_hits_2 = 4
)

library(rstan)
model <- sampling(stan_model, data = stan_data)
model
```

To get the Bayesian p-value (to compare the two procedures).

```{r}
draws <- rstan::extract(model)

# p(men are more left handed than women)
mean(draws$diff > 0)

# p("null" hypthosis)
mean(draws$diff <= 0)
```

Use ggmcmc is to visualize the effects.

```{r}
library(ggmcmc)

# Get ggmcmc's tidy data of the model
ggs <- ggs(model)

ci(ggs, thick_ci = c(0.05, 0.95), thin_ci = c(0.025, 0.975)) %>% 
  knitr::kable(digits = 2)

ggs_density(ggs) + facet_grid(Parameter ~ .)

ggs_caterpillar(ggs, line = 0)
```

## Try it out with a regression model

```{r}
library(rstanarm)
dfw <- tidyr::spread(df, Handedness, n)
reg <- stan_glm(
  cbind(left, right) ~ Sex, 
  family = binomial, 
  data = dfw)
summary(reg)

pp_reg <- posterior_linpred(reg) %>% 
  as.data.frame() %>% 
  setNames(c("female_left", "male_left")) %>% 
  mutate(female_rate = plogis(female_left),
         male_rate = plogis(male_left), 
         diff = male_rate - female_rate)

round(quantile(pp_reg$diff, c(.05, .1, .25, .5, .75, .9, .95)), 2)

pp_reg_long <- pp_reg %>% 
  select(male_rate, female_rate, diff) %>% 
  tidyr::gather(variable, value)

ggplot(pp_reg_long) + 
  aes(x = value) + 
  geom_density() + 
  facet_grid(variable ~ .)
```


